agent.sources = r1 r2
agent.channels = c1 c2
agent.sinks = k1 k2

# Describe/configure the source

agent.sources.r1.type = org.apache.flume.source.kafka.KafkaSource
agent.sources.r1.batchSize = 5000
agent.sources.r1.batchDurationMillis = 100
agent.sources.r1.kafka.bootstrap.servers = localhost:9092
agent.sources.r1.kafka.topics = bigdata-tweets
agent.sources.r1.kafka.consumer.group.id = flume-consumer

# Describe the sink
agent.sinks.k1.type = logger

# Use a channel which buffers events in memory
agent.channels.c1.type = memory
agent.channels.c1.capacity = 10000
agent.channels.c1.transactionCapacity = 10000

# Bind the source and sink to the channel
agent.sources.r1.channels = c1
agent.sinks.k1.channel = c1

agent.sinks.k1.type = org.apache.kudu.flume.sink.KuduSink
agent.sinks.k1.producer =  com.example.kudu.flume.sink.JsonKuduOperationsProducer2
agent.sinks.k1.masterAddresses = master01:7051,master02:7051,master03:7051
agent.sinks.k1.tableName = impala::default.twitter_bigdata
agent.sinks.k1.batchSize = 50


######USER
# Describe/configure the source

agent.sources.r2.type = org.apache.flume.source.kafka.KafkaSource
agent.sources.r2.batchSize = 5000
agent.sources.r2.batchDurationMillis = 100
agent.sources.r2.kafka.bootstrap.servers = localhost:9092
agent.sources.r2.kafka.topics = bigdata-tweets-user
agent.sources.r2.kafka.consumer.group.id = flume-consumer-2

# Describe the sink
agent.sinks.k2.type = logger

# Use a channel which buffers events in memory
agent.channels.c2.type = memory
agent.channels.c2.capacity = 10000
agent.channels.c2.transactionCapacity = 10000

# Bind the source and sink to the channel
agent.sources.r2.channels = c2
agent.sinks.k2.channel = c2

agent.sinks.k2.type = org.apache.kudu.flume.sink.KuduSink
agent.sinks.k2.producer =  com.example.kudu.flume.sink.JsonKuduOperationsProducer2
agent.sinks.k2.masterAddresses = master01:7051,master02:7051,master03:7051
agent.sinks.k2.tableName = impala::default.twitter_bigdata_user
agent.sinks.k2.batchSize = 50

